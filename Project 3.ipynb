{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3\n",
    "\n",
    "Haig Bedros, Nori Selina, Julia Ferris, Matthew Roland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 3 - Your project should be submitted (as a Jupyter Notebook via GitHub) by end of the due date. The group should present their code and findings in our meetup. The ability to be an effective member of a virtual team is highly valued in the data science job market.  \n",
    "\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. \n",
    "\n",
    "Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set.\n",
    "\n",
    "How does the performance on the test set compare to the performance on the dev-test set?\n",
    "\n",
    "Is this what you'd expect?\n",
    "\n",
    "Source: Natural Language Processing with Python, exercise 6.10.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a function to extract gender features\n",
    "\n",
    "This function simply returns both the last character of a word and the last 2 characters of a word, respectively. For our model, we will be using these suffices to classify whether a name is masculine or feminine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'suffix1': word[-1],\n",
    "            'suffix2': word[-2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Names Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#nltk.download()\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m names \u001b[38;5;241m=\u001b[39m ([(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmale\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmale.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m      3\u001b[0m          [(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfemale\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfemale.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[0;32m      4\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m12345\u001b[39m)\n\u001b[0;32m      5\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(names)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "#nltk.download()\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "         [(name, 'female') for name in names.words('female.txt')])\n",
    "random.seed(12345)\n",
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Train, Test, and Development Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set: 0.7605877268798618\n",
      "Accuracy of dev test set: 0.7305389221556886\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features(n), g) for (n,g) in names]\n",
    "\n",
    "train_set, test_set, dev_test = featuresets[0:501], featuresets[1002:], featuresets[501:1002]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(\"Accuracy of test set:\", nltk.classify.accuracy(classifier, test_set))\n",
    "print('Accuracy of dev test set:', nltk.classify.accuracy(classifier, dev_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this classifier performs with an accuracy of ~.75, which is sufficient, but can certainly be improved upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Aeriel                        \n",
      "correct=female   guess=male     name=Aileen                        \n",
      "correct=female   guess=male     name=Alisun                        \n",
      "correct=female   guess=male     name=Allison                       \n",
      "correct=female   guess=male     name=Amber                         \n",
      "correct=female   guess=male     name=Ariel                         \n",
      "correct=female   guess=male     name=Brandais                      \n",
      "correct=female   guess=male     name=Brittan                       \n",
      "correct=female   guess=male     name=Caitrin                       \n",
      "correct=female   guess=male     name=Carmel                        \n",
      "correct=female   guess=male     name=Caroljean                     \n",
      "correct=female   guess=male     name=Cary                          \n",
      "correct=female   guess=male     name=Charmain                      \n",
      "correct=female   guess=male     name=Christel                      \n",
      "correct=female   guess=male     name=Christian                     \n",
      "correct=female   guess=male     name=Chrystal                      \n",
      "correct=female   guess=male     name=Ciel                          \n",
      "correct=female   guess=male     name=Cleo                          \n",
      "correct=female   guess=male     name=Clo                           \n",
      "correct=female   guess=male     name=Corabel                       \n",
      "correct=female   guess=male     name=Crystal                       \n",
      "correct=female   guess=male     name=Daffy                         \n",
      "correct=female   guess=male     name=Deb                           \n",
      "correct=female   guess=male     name=Demetris                      \n",
      "correct=female   guess=male     name=Devin                         \n",
      "correct=female   guess=male     name=Dolley                        \n",
      "correct=female   guess=male     name=Dyan                          \n",
      "correct=female   guess=male     name=Eilis                         \n",
      "correct=female   guess=male     name=Emmey                         \n",
      "correct=female   guess=male     name=Fern                          \n",
      "correct=female   guess=male     name=Fey                           \n",
      "correct=female   guess=male     name=Flower                        \n",
      "correct=female   guess=male     name=Georgiamay                    \n",
      "correct=female   guess=male     name=Glen                          \n",
      "correct=female   guess=male     name=Glennis                       \n",
      "correct=female   guess=male     name=Gretal                        \n",
      "correct=female   guess=male     name=Grissel                       \n",
      "correct=female   guess=male     name=Hannah                        \n",
      "correct=female   guess=male     name=Harley                        \n",
      "correct=female   guess=male     name=Inez                          \n",
      "correct=female   guess=male     name=Ivett                         \n",
      "correct=female   guess=male     name=Janot                         \n",
      "correct=female   guess=male     name=Jen                           \n",
      "correct=female   guess=male     name=Joey                          \n",
      "correct=female   guess=male     name=Karin                         \n",
      "correct=female   guess=male     name=Kiersten                      \n",
      "correct=female   guess=male     name=Kit                           \n",
      "correct=female   guess=male     name=Kristan                       \n",
      "correct=female   guess=male     name=Lainey                        \n",
      "correct=female   guess=male     name=Leiah                         \n",
      "correct=female   guess=male     name=Linnet                        \n",
      "correct=female   guess=male     name=Lois                          \n",
      "correct=female   guess=male     name=Malcah                        \n",
      "correct=female   guess=male     name=Marion                        \n",
      "correct=female   guess=male     name=Marleen                       \n",
      "correct=female   guess=male     name=Mavis                         \n",
      "correct=female   guess=male     name=Mehetabel                     \n",
      "correct=female   guess=male     name=Mellisent                     \n",
      "correct=female   guess=male     name=Meriel                        \n",
      "correct=female   guess=male     name=Mildred                       \n",
      "correct=female   guess=male     name=Milicent                      \n",
      "correct=female   guess=male     name=Miriam                        \n",
      "correct=female   guess=male     name=Nicol                         \n",
      "correct=female   guess=male     name=Phillis                       \n",
      "correct=female   guess=male     name=Rakel                         \n",
      "correct=female   guess=male     name=Ray                           \n",
      "correct=female   guess=male     name=Shannah                       \n",
      "correct=female   guess=male     name=Sheilah                       \n",
      "correct=female   guess=male     name=Sherry                        \n",
      "correct=female   guess=male     name=Sileas                        \n",
      "correct=female   guess=male     name=Susan                         \n",
      "correct=female   guess=male     name=Ted                           \n",
      "correct=female   guess=male     name=Tiffi                         \n",
      "correct=female   guess=male     name=Venus                         \n",
      "correct=male     guess=female   name=Aristotle                     \n",
      "correct=male     guess=female   name=Artie                         \n",
      "correct=male     guess=female   name=Averill                       \n",
      "correct=male     guess=female   name=Bealle                        \n",
      "correct=male     guess=female   name=Beowulf                       \n",
      "correct=male     guess=female   name=Brady                         \n",
      "correct=male     guess=female   name=Bruce                         \n",
      "correct=male     guess=female   name=Bryce                         \n",
      "correct=male     guess=female   name=Cammy                         \n",
      "correct=male     guess=female   name=Carleigh                      \n",
      "correct=male     guess=female   name=Cass                          \n",
      "correct=male     guess=female   name=Chance                        \n",
      "correct=male     guess=female   name=Che                           \n",
      "correct=male     guess=female   name=Collins                       \n",
      "correct=male     guess=female   name=Cortese                       \n",
      "correct=male     guess=female   name=Dane                          \n",
      "correct=male     guess=female   name=Dante                         \n",
      "correct=male     guess=female   name=Darrell                       \n",
      "correct=male     guess=female   name=Derby                         \n",
      "correct=male     guess=female   name=Duane                         \n",
      "correct=male     guess=female   name=Elihu                         \n",
      "correct=male     guess=female   name=Elmore                        \n",
      "correct=male     guess=female   name=Giavani                       \n",
      "correct=male     guess=female   name=Giorgi                        \n",
      "correct=male     guess=female   name=Henrie                        \n",
      "correct=male     guess=female   name=Herby                         \n",
      "correct=male     guess=female   name=Higgins                       \n",
      "correct=male     guess=female   name=Irving                        \n",
      "correct=male     guess=female   name=Jackie                        \n",
      "correct=male     guess=female   name=Jess                          \n",
      "correct=male     guess=female   name=Joseph                        \n",
      "correct=male     guess=female   name=Kenneth                       \n",
      "correct=male     guess=female   name=Lemmy                         \n",
      "correct=male     guess=female   name=Lorenzo                       \n",
      "correct=male     guess=female   name=Maurie                        \n",
      "correct=male     guess=female   name=Mendie                        \n",
      "correct=male     guess=female   name=Michail                       \n",
      "correct=male     guess=female   name=Murphy                        \n",
      "correct=male     guess=female   name=Odie                          \n",
      "correct=male     guess=female   name=Osborne                       \n",
      "correct=male     guess=female   name=Oswell                        \n",
      "correct=male     guess=female   name=Otho                          \n",
      "correct=male     guess=female   name=Pennie                        \n",
      "correct=male     guess=female   name=Quincy                        \n",
      "correct=male     guess=female   name=Reube                         \n",
      "correct=male     guess=female   name=Russell                       \n",
      "correct=male     guess=female   name=Sawyere                       \n",
      "correct=male     guess=female   name=Shayne                        \n",
      "correct=male     guess=female   name=Tally                         \n",
      "correct=male     guess=female   name=Tammie                        \n",
      "correct=male     guess=female   name=Tammy                         \n",
      "correct=male     guess=female   name=Temp                          \n",
      "correct=male     guess=female   name=Tome                          \n",
      "correct=male     guess=female   name=Tremaine                      \n",
      "correct=male     guess=female   name=Uli                           \n",
      "correct=male     guess=female   name=Verne                         \n",
      "correct=male     guess=female   name=Warde                         \n",
      "correct=male     guess=female   name=Welbie                        \n",
      "correct=male     guess=female   name=Wendall                       \n",
      "correct=male     guess=female   name=Westleigh                     \n",
      "correct=male     guess=female   name=Zach                          \n"
     ]
    }
   ],
   "source": [
    "dev_test_names = names[501:1002]\n",
    "\n",
    "errors = []\n",
    "for (name, tag) in dev_test_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append((tag, guess, name))\n",
    "\n",
    "for (tag, guess, name) in sorted(errors):\n",
    "    print('correct={:<8} guess={:<8} name={:<30}'.format(tag, guess, name))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of errors produced can give us hints regarding ways to modify our model. For instance, we can see that the model appears to guess male names too often based on the last 2 characters of the string. Perhaps incorporating the first character of a string may ameliorate this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining the Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several new features are added below with the goal of improving the model. Suffixes, prefixes, word length, vowels, consonants, and vowels in the suffix were all features added to the classification model. These changes were based on the errors of the previous attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features_2(word):\n",
    "    return {'suffix1': word[-1],\n",
    "            'suffix2': word[-2],\n",
    "            'prefix1': word[0],\n",
    "            'prefix2': word[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set: 0.7574186113511956\n",
      "Accuracy of dev test set: 0.7485029940119761\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features_2(n), g) for (n,g) in names]\n",
    "\n",
    "train_set_2, test_set_2, dev_test_2 = featuresets[0:501], featuresets[1002:], featuresets[501:1002]\n",
    "\n",
    "classifier_2 = nltk.NaiveBayesClassifier.train(train_set_2)\n",
    "\n",
    "print(\"Accuracy of test set:\", nltk.classify.accuracy(classifier_2, test_set_2))\n",
    "print('Accuracy of dev test set:', nltk.classify.accuracy(classifier_2, dev_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features_3(word):\n",
    "    return {'suffix1': word[-1],\n",
    "            'suffix2': word[-2],\n",
    "            'prefix1': word[0],\n",
    "            'prefix2': word[1],\n",
    "            'length': len(word),\n",
    "            'vowels': sum(1 for v in word.lower() if v in 'aeiou')}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set: 0.7662057044079515\n",
      "Accuracy of dev test set: 0.7385229540918163\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features_3(n), g) for (n,g) in names]\n",
    "\n",
    "train_set_3, test_set_3, dev_test_3 = featuresets[0:501], featuresets[1002:], featuresets[501:1002]\n",
    "\n",
    "classifier_3 = nltk.NaiveBayesClassifier.train(train_set_3)\n",
    "\n",
    "print(\"Accuracy of test set:\", nltk.classify.accuracy(classifier_2, test_set_3))\n",
    "print('Accuracy of dev test set:', nltk.classify.accuracy(classifier_2, dev_test_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features_4(word):\n",
    "    return {'suffix1': word[-1],\n",
    "            'suffix2': word[-2],\n",
    "            'prefix1': word[0],\n",
    "            'prefix2': word[1],\n",
    "            'length': len(word),\n",
    "            'vowels': sum(1 for v in word.lower() if v in 'aeiou'),\n",
    "            'consonants': sum(1 for c in word.lower() if c not in 'aeiou'),\n",
    "            'suffix_vowel': word[0] in 'aeiou'}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set: 0.7623163353500432\n",
      "Accuracy of dev test set: 0.7385229540918163\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features_4(n), g) for (n,g) in names]\n",
    "\n",
    "train_set_4, test_set_4, dev_test_4 = featuresets[0:501], featuresets[1002:], featuresets[501:1002]\n",
    "\n",
    "classifier_4 = nltk.NaiveBayesClassifier.train(train_set_4)\n",
    "\n",
    "print(\"Accuracy of test set:\", nltk.classify.accuracy(classifier_4, test_set_4))\n",
    "print('Accuracy of dev test set:', nltk.classify.accuracy(classifier_2, dev_test_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "How does the performance on the test set compare to the performance on the dev-test set?\n",
    "\n",
    "- When the classifier was originally checked for accuracies, the accuracy on the test set was nearly identical to the performance on the dev-test set. This shows that the classifier was consistent in its abilities to determine gender. The high accuracy of over 70% showed that the model was relatively good at determining if the name was male or female, but it could be improved upon.\n",
    "- When the classifier was trained  using more features, the accuracy on the test sets were, again, nearly identical to the performance on the dev-test set. The difference in accuracies was slightly more than the first classifier, but they were still very close. This shows the classifier was also consistent in its abilities to determine gender. It did not improve much compared to the original classifier, but it still showed a strong accuracy.\n",
    "\n",
    "Is this what you'd expect?\n",
    "\n",
    "- This was expected based on the results from the textbook. The accuracies were very similar in the example shown.\n",
    "- Without consideration for the textbook, we assumed the dev-test set would have a similar accuracy to the test set in the first classification model because neither set was used to train the model. The model should be consistent across many different data sets. Also, we assumed the dev-test set would be slightly more accurate than the test set in the second classification model because the errors made on the dev-test set were used to help decide on the features added in the second model. Therefore, the results were also as expected even without considering the accuracies shown in the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Scikit-Learn for Classification\n",
    "\n",
    "Now, we will compare the performance of classifiers from scikit-learn. Specifically, we will build a logistic regression model and a random forest model to see how these compare to nltk's naivebayes classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we will create a new feature selection system that will act similarly to the one we created previously, using the length of each name, as well as the first and last two letters of each name, vowels, consonants, and whether the suffix has a vowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "names_df = pd.DataFrame(names)\n",
    "\n",
    "names_df.rename(columns = {0: 'name', 1: 'gender'}, inplace =  True)\n",
    "\n",
    "def gender_features_sci(words):\n",
    "    features = []\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        features.append({\n",
    "            'length': len(word),\n",
    "            'suffix1': word[-1],\n",
    "            'suffix2': word[-2],\n",
    "            'prefix1': word[0],\n",
    "            'prefix2': word[1],\n",
    "            'vowels': sum(1 for v in word if v in 'aeiou'),\n",
    "            'consonants': sum(1 for c in word if c not in 'aeiou'),\n",
    "            'suffix_vowel': 1 if word[-1] in 'aeiou' else 0\n",
    "        })\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will apply this feature selection function to the dataframe and partition our data into predictor and outcome dataframes. Because of sklearn's logic, we will have to code dummy variables for the model to properly read our data. Then, we will properly encode our binary male/female outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = gender_features_sci(names_df['name'])\n",
    "y = names_df['gender']\n",
    "\n",
    "X = pd.get_dummies(X, columns = ['suffix1', 'suffix2', 'prefix1', 'prefix2', 'vowels', 'consonants', 'suffix_vowel'])\n",
    "\n",
    "label = LabelEncoder()\n",
    "label.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will build the actual logistic regression model by first splitting our data, followed by fitting the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8024328859060402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.83      0.86      0.85      1499\n",
      "        male       0.75      0.71      0.73       885\n",
      "\n",
      "    accuracy                           0.80      2384\n",
      "   macro avg       0.79      0.78      0.79      2384\n",
      "weighted avg       0.80      0.80      0.80      2384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "reg_model = LogisticRegression(max_iter = 300)\n",
    "reg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred, target_names=label.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our model performed rather well, obtaining an accuracy of around 80%, which is slightly better compared to nltk's naive bayesian model. Furthermore, after diagnosing the classification report, it seems that our model performs better when classifying female outcomes compared to males.\n",
    "\n",
    "Now, we will compare the performance of our regression to a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.777265100671141\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.82      0.83      0.82      1499\n",
      "        male       0.70      0.69      0.70       885\n",
      "\n",
      "    accuracy                           0.78      2384\n",
      "   macro avg       0.76      0.76      0.76      2384\n",
      "weighted avg       0.78      0.78      0.78      2384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_forest = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_forest)\n",
    "\n",
    "print('Accuracy', accuracy)\n",
    "print(classification_report(y_test, y_pred_forest, target_names=label.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would appear that our logistic regression model performs marginally better than our random forest model, with a 2% difference in accuracy. Notably, both models possess a bias toward more often correctly predicting names that belong to female observations compared to males; however, this difference appears to be somewhat more pronounced in the random forest model. Perhaps the disparity in predicted outcomes is a result of features that were not explored in our models, such as vowel and consonant composition. Clearly, more complex models should be constructed for the construction of an enhanced, generalizable classification model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
